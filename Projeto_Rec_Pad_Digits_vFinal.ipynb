{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_Rec_Pad_Digits_vFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12CDNn7WiQ0NnePAi5KKNixSyRVMjRxew",
      "authorship_tag": "ABX9TyPPI1UxZYVnOIDWaHT9jQ0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teotavares2/RecPad/blob/main/Projeto_Rec_Pad_Digits_vFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPynu0H4tNwB"
      },
      "source": [
        "# Digits vFinal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WTeyXVxtNwC"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import f1_score,recall_score, precision_score, confusion_matrix, roc_curve, classification_report, accuracy_score\n",
        "from time import time,sleep\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "%matplotlib inline\n",
        "import _pickle as cPickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O26VOT4wRjt"
      },
      "source": [
        "# Classifiers\n",
        "\n",
        "classifiers =[]\n",
        "mlp = MLPClassifier(random_state=42, verbose=1, batch_size=64, max_iter=400,early_stopping = True)\n",
        "classifiers.append(mlp)\n",
        "\n",
        "knn = KNeighborsClassifier(n_jobs=-1) #algorithm='auto'\n",
        "classifiers.append(knn)\n",
        "\n",
        "svm = SVC(probability=True)\n",
        "classifiers.append(svm)\n",
        "\n",
        "# Classifiers Parameters\n",
        "parameters=[]\n",
        "parameters_mlp = {'activation': ['identity','logistic','tanh','relu'], \n",
        "                  'solver':['lbfgs','sgd','adam'], \n",
        "                  'learning_rate':['constant','invscaling','adaptive'],\n",
        "                  'alpha': [0.01,0.001,0.0001]  \n",
        "                  }\n",
        "parameters.append(parameters_mlp)\n",
        "parameters_knn = {\"n_neighbors\": [1,2,4,8,16,32], \n",
        "                 \"weights\": ['uniform','distance'],\n",
        "                 \"algorithm\":['ball_tree', 'kd_tree', 'brute'],\n",
        "                 \"p\":[1,2]\n",
        "                  }\n",
        "parameters.append(parameters_knn)\n",
        "parameters_svm = {\"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "                 'decision_function_shape':('ovo', 'ovr'),\n",
        "                 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "                 'C':[0.1,1,10,100,1000] \n",
        "                 }\n",
        "parameters.append(parameters_svm)\n",
        "\n",
        "# Classifiers Names\n",
        "\n",
        "names = ['MLPClassifier',\n",
        "        'KNeighborsClassifier',\n",
        "        'SupportVectorClassifier',\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJE3yvDmwuHW"
      },
      "source": [
        "# Dataset Digits\n",
        "\n",
        "digits = load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,test_size=0.20, shuffle=True)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Best Classifiers with GridSearchCV\n",
        "\n",
        "path='/content/drive/MyDrive/RecPad/Models/'\n",
        "\n",
        "def gridSearchCV(models,params,count):\n",
        "    best_models=[]\n",
        "    for i in tqdm(range(0,count)):\n",
        "        model_grid = GridSearchCV(models[i], parameters[i], n_jobs=-1, verbose=1, cv=5)\n",
        "        model_grid.fit(X_train,y_train)\n",
        "        best_models.append(model_grid.best_estimator_)\n",
        "    return best_models\n",
        "\n",
        "best_model_list = gridSearchCV(classifiers,parameters,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EABHoagUle6"
      },
      "source": [
        "# Gerando o cabeçalho\n",
        "log_accuracy = open('/content/drive/MyDrive/RecPad/Logs/accuracy.csv','a')\n",
        "log_time = open('/content/drive/MyDrive/RecPad/Logs/time.log','a')\n",
        "\n",
        "\n",
        "# Unique estimators\n",
        "for x in range(len(best_model_list)):\n",
        "  log_accuracy.write(str(names[x])+',')\n",
        "  log_time.write(str(names[x])+',')\n",
        "\n",
        "\n",
        "# Votting Hard\n",
        "log_accuracy.write('VottingHard,')\n",
        "log_time.write('VottingHard,')\n",
        "\n",
        "# Votting Soft\n",
        "log_accuracy.write('VottingSoft,')\n",
        "log_time.write('VottingSoft,')\n",
        "\n",
        "# Stacking\n",
        "for x in range(len(best_model_list)):\n",
        "  for y in range(len(best_model_list)):\n",
        "    if x!=y:\n",
        "      log_accuracy.write('{}{},'.format(names[x],names[y]))\n",
        "      log_time.write('{}{},'.format(names[x],names[y]))\n",
        "\n",
        "log_accuracy.write('\\n')\n",
        "log_time.write('\\n')\n",
        "\n",
        "log_accuracy.close()\n",
        "log_time.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw1NkFIHVxzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7437c2c9-01cf-4a5a-fb30-08de5b040dc0"
      },
      "source": [
        "# Best Estimators log and print\n",
        "log_file = open('/content/drive/MyDrive/RecPad/Logs/digits_best_estimators.log','a')\n",
        "log_file.write(\"\\nThe best estimators are:\\n\")\n",
        "for i in range(len(classifiers)):\n",
        "  log_file.write(\"\\n\")\n",
        "  log_file.write(str(best_model_list[i]))\n",
        "log_file.close() \n",
        "\n",
        "print(str(best_model_list[0])+'\\n')\n",
        "print(str(best_model_list[1])+'\\n')\n",
        "print(str(best_model_list[2])+'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier(activation='logistic', alpha=0.01, batch_size=64, beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=400,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=42, shuffle=True, solver='lbfgs',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
            "\n",
            "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=-1, n_neighbors=1, p=3,\n",
            "                     weights='uniform')\n",
            "\n",
            "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovo', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrjK6t5fcWGz"
      },
      "source": [
        "# # Melhores estimadores\n",
        "\n",
        "# # MLPClassifier\n",
        "# best_model_list[0] = MLPClassifier(activation='logistic', alpha=0.01, batch_size=64, beta_1=0.9,\n",
        "#               beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
        "#               hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "#               learning_rate_init=0.001, max_fun=15000, max_iter=400,\n",
        "#               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "#               power_t=0.5, random_state=42, shuffle=True, solver='lbfgs',\n",
        "#               tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
        "\n",
        "# # KNeighborsClassifier\n",
        "# best_model_list[1] = KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
        "#                      metric_params=None, n_jobs=-1, n_neighbors=1, p=3,\n",
        "#                      weights='uniform')\n",
        "\n",
        "# # SupportVectorClassifier\n",
        "# best_model_list[2] = SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "#     decision_function_shape='ovo', degree=3, gamma=0.1, kernel='rbf',\n",
        "#     max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
        "#     verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzenSN_tPvpv"
      },
      "source": [
        "# Experiment\n",
        "from time import time\n",
        "\n",
        "for i in range(30):\n",
        "  digits = load_digits()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.20, shuffle=True)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  log_accuracy = open('/content/drive/MyDrive/RecPad/Logs/accuracy.csv','a')\n",
        "  log_time = open('/content/drive/MyDrive/RecPad/Logs/time.csv','a')\n",
        "\n",
        "\n",
        "  # Unique estimators\n",
        "  for x in range(len(best_model_list)):\n",
        "    model = best_model_list[x]\n",
        "    t0 = time()\n",
        "    model.fit(X_train,y_train)\n",
        "    t1 = (time() - t0)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "    log_accuracy.write('{:.2f},'.format(accuracy))\n",
        "    log_time.write('{:.2f},'.format(t1))\n",
        "\n",
        "\n",
        "  # Voting Hard\n",
        "  vot_clf = VotingClassifier(estimators=[('mlp', best_model_list[0]),\n",
        "                                        ('knn', best_model_list[1]),\n",
        "                                        ('svm', best_model_list[2])\n",
        "                                        ], \n",
        "                            voting='hard',n_jobs=-1)\n",
        "  t0 = time()\n",
        "  vot_clf.fit(X_train,y_train)\n",
        "  t1 = (time() - t0)\n",
        "  y_pred = vot_clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "  log_accuracy.write('{:.2f},'.format(accuracy))\n",
        "  log_time.write('{:.2f},'.format(t1))\n",
        "\n",
        "  # Votting Soft\n",
        "  vot_clf = VotingClassifier(estimators=[('mlp', best_model_list[0]),\n",
        "                                        ('knn', best_model_list[1]),\n",
        "                                        ('svm', best_model_list[2])\n",
        "                                        ], \n",
        "                            voting='soft',n_jobs=-1)\n",
        "  t0 = time()\n",
        "  vot_clf.fit(X_train,y_train)\n",
        "  t1 = (time() - t0)\n",
        "  y_pred = vot_clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "  log_accuracy.write('{:.2f},'.format(accuracy))\n",
        "  log_time.write('{:.2f},'.format(t1))\n",
        "\n",
        "  # Stacking\n",
        "  for x in range(len(best_model_list)):\n",
        "    for y in range(len(best_model_list)):\n",
        "      if x!=y:\n",
        "        estimators = [(names[x],best_model_list[x])]\n",
        "        stacking = StackingClassifier(estimators=estimators,final_estimator=best_model_list[y])\n",
        "        t0 = time()\n",
        "        stacking.fit(X_train, y_train)\n",
        "        t1 = (time() - t0)\n",
        "        y_pred = stacking.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        log_accuracy.write('{:.2f},'.format(accuracy))\n",
        "        log_time.write('{:.2f},'.format(t1))\n",
        "\n",
        "  log_accuracy.write('\\n')\n",
        "  log_time.write('\\n')\n",
        "\n",
        "  log_accuracy.close()\n",
        "  log_time.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUqjTDTerRBq",
        "outputId": "7fd6788b-f2a4-4bcb-dd4b-555c3f008960"
      },
      "source": [
        "pd.read_csv('/content/drive/MyDrive/RecPad/Logs/accuracy.csv').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3YSjmUkkUAt"
      },
      "source": [
        "log_accuracy = '/content/drive/MyDrive/RecPad/Logs/accuracy.csv'\n",
        "log_time = '/content/drive/MyDrive/RecPad/Logs/time.csv'\n",
        "\n",
        "accuracy = pd.read_csv(log_accuracy)\n",
        "time = pd.read_csv(log_time)\n",
        "\n",
        "print(accuracy.mean(),'\\n\\n',time.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM5XsKj5KctB"
      },
      "source": [
        "# Predição do melhor modelo\n",
        "\n",
        "# clf.fit(X_train, y_train)\n",
        "# predicted = clf.predict(X_test)\n",
        "\n",
        "# _, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "# for ax, image, prediction in zip(axes, X_test, predicted):\n",
        "#     ax.set_axis_off()\n",
        "#     image = image.reshape(8, 8)\n",
        "#     ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "#     ax.set_title(f'Prediction: {prediction}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF9-GtUWya3C"
      },
      "source": [
        "# Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qawOTGAJatmo"
      },
      "source": [
        "from time import time\n",
        "\n",
        "best_model = SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "                decision_function_shape='ovo', degree=3, gamma=0.1, kernel='rbf',\n",
        "                max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
        "                verbose=False)\n",
        "\n",
        "estimator = [('SupportVectorClassifier',best_model)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS2ju-eYy2zp"
      },
      "source": [
        "# MLPClassifier\n",
        "\n",
        "# Parâmetros\n",
        "activation = ['identity','logistic','tanh','relu']\n",
        "solver = ['lbfgs','sgd','adam']\n",
        "learning_rate = ['constant','invscaling','adaptive']\n",
        "alpha = [0.01,0.001,0.0001]  \n",
        "digits = load_digits() # dataset\n",
        "# Experimento \n",
        "rounds = 30\n",
        "count = 0\n",
        "\n",
        "for x in range(len(activation)): \n",
        "  for y in range(len(solver)):\n",
        "    for z in range(len(learning_rate)):\n",
        "      for w in range(len(alpha)):\n",
        "        \n",
        "        count = count + 1\n",
        "        file =  '/content/drive/MyDrive/RecPad/Logs/SupportVectorClassifierMLPClassifier'+str(count)+'.csv'\n",
        "        log = open(file,'a')\n",
        "        log.write('{},{},{},{},{},{},{}\\n'.format('Classifier','activation','solver','learning_rate','alpha','time','accuracy'))\n",
        "        \n",
        "        for i in range(rounds):\n",
        "          \n",
        "          X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.20, shuffle=True)\n",
        "          scaler = MinMaxScaler()\n",
        "          X_train = scaler.fit_transform(X_train)\n",
        "          X_test = scaler.transform(X_test)\n",
        "\n",
        "          model =  MLPClassifier(activation=activation[x], alpha=alpha[w], batch_size=64, beta_1=0.9,\n",
        "                beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
        "                hidden_layer_sizes=(100,), learning_rate=learning_rate[z],\n",
        "                learning_rate_init=0.001, max_fun=15000, max_iter=400,\n",
        "                momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
        "                power_t=0.5, random_state=42, shuffle=True, solver=solver[y],\n",
        "                tol=0.0001, validation_fraction=0.1, verbose=False, warm_start=False)\n",
        "\n",
        "          stacking = StackingClassifier(estimators=estimator,final_estimator=model)\n",
        "          stacking.fit(X_train,y_train)\n",
        "          t0 = time()\n",
        "          stacking.fit(X_train, y_train)\n",
        "          t1 = (time() - t0)\n",
        "          y_pred = stacking.predict(X_test)\n",
        "          accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "          log.write('{},{},{},{},{:.4f},{:.2f},{:.2f}\\n'.format('SupportVectorClassifierMLPClassifier',activation[x],solver[y],learning_rate[z],alpha[w],t1,accuracy))\n",
        "        log.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGNT9LGyfA7a"
      },
      "source": [
        "logs = open('/content/drive/MyDrive/RecPad/SupportVectorClassifierMLPClassifier.csv','a')\n",
        "for i in range(1,109):\n",
        "  log = '/content/drive/MyDrive/RecPad/Logs/SupportVectorClassifierMLPClassifier'+str(i)+'.csv'\n",
        "  df = pd.read_csv(log)\n",
        "  df.reset_index(inplace=True)\n",
        "  # print('{},{},{},{},{},{},{:.2f}%,{}s' .format(df.iloc[0,1], df.iloc[0,2], df.iloc[0,3], df.iloc[0,4],df.iloc[0,5],df.iloc[0,6], df['accuracy'].mean(), df['time'].mean()))\n",
        "  logs.write('{},{},{},{},{},{},{:.2f}%,{}s\\n' .format(df.iloc[0,1], df.iloc[0,2], df.iloc[0,3], df.iloc[0,4],df.iloc[0,5],df.iloc[0,6], df['accuracy'].mean(), df['time'].mean()))\n",
        "logs.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jnpj_Jy5VCO"
      },
      "source": [
        "# KNeighborsClassifier\n",
        "\n",
        "# Parâmetros\n",
        "n_neighbors = [1,2,4,8,16,32] \n",
        "weights = ['uniform','distance']\n",
        "algorithm = ['ball_tree', 'kd_tree', 'brute']\n",
        "p = [1,2,3]\n",
        "digits = load_digits() # dataset\n",
        "\n",
        "# Experimento \n",
        "rounds = 30\n",
        "count = 0\n",
        "\n",
        "for x in range(len(n_neighbors)): \n",
        "  for y in range(len(weights)):\n",
        "    for z in range(len(algorithm)):\n",
        "      for w in range(len(p)):\n",
        "       \n",
        "        count = count + 1\n",
        "        file =  '/content/drive/MyDrive/RecPad/Logs/SupportVectorClassifierKNeighborsClassifier'+str(count)+'.csv'\n",
        "        log = open(file,'a')\n",
        "        log.write('{},{},{},{},{},{},{}\\n'.format('Classifier','n_neighbors','weights','algorithm','p','time','accuracy'))\n",
        "     \n",
        "        for i in range(rounds):\n",
        "\n",
        "          X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.20, shuffle=True)\n",
        "          scaler = MinMaxScaler()\n",
        "          X_train = scaler.fit_transform(X_train)\n",
        "          X_test = scaler.transform(X_test)\n",
        "\n",
        "          model = KNeighborsClassifier(algorithm=algorithm[z], leaf_size=30, metric='minkowski',\n",
        "                                       metric_params=None, n_jobs=-1, n_neighbors=n_neighbors[x], p=p[w],\n",
        "                                       weights=weights[y])\n",
        "\n",
        "          stacking = StackingClassifier(estimators=estimator,final_estimator=model)\n",
        "          stacking.fit(X_train,y_train)\n",
        "          t0 = time()\n",
        "          stacking.fit(X_train, y_train)\n",
        "          t1 = (time() - t0)\n",
        "          y_pred = stacking.predict(X_test)\n",
        "          accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "          log.write('{},{},{},{},{},{:.2f},{:.2f}\\n'.format('SupportVectorClassifierKNeighborsClassifier',n_neighbors[x],weights[y],algorithm[z],p[w],t1,accuracy))\n",
        "        log.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocr6beLzcJmI"
      },
      "source": [
        "logs = open('/content/drive/MyDrive/RecPad/SupportVectorClassifierKNeighborsClassifier.csv','a')\n",
        "for i in range(1,109):\n",
        "  log = '/content/drive/MyDrive/RecPad/Logs/SupportVectorClassifierKNeighborsClassifier'+str(i)+'.csv'\n",
        "  df = pd.read_csv(log)\n",
        "  df.reset_index(inplace=True)\n",
        "  # print('{},{},{},{},{},{},{:.2f}%,{}s' .format(df.iloc[0,1], df.iloc[0,2], df.iloc[0,3], df.iloc[0,4],df.iloc[0,5],df.iloc[0,6], df['accuracy'].mean(), df['time'].mean()))\n",
        "  logs.write('{},{},{},{},{},{},{:.2f}%,{}s\\n' .format(df.iloc[0,1], df.iloc[0,2], df.iloc[0,3], df.iloc[0,4],df.iloc[0,5],df.iloc[0,6], df['accuracy'].mean(), df['time'].mean()))\n",
        "logs.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSnmfX0tT1Rs"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "log_SupportVectorClassifier = pd.read_csv('/content/drive/MyDrive/RecPad/SupportVectorClassifier.csv','a')\n",
        "log_Ensemble = pd.read_csv('/content/drive/MyDrive/RecPad/VotingHard.csv','a')\n",
        "\n",
        "SupportVectorClassifier = log_SupportVectorClassifier['accuracy']\n",
        "Ensemble = log_Ensemble['accuracy']\n",
        "\n",
        "stats.wilcoxon(Best_Estimator, Ensemble)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}